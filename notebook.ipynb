{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d_HSB9yt5HKA"
   },
   "source": [
    "## Computer Vision(CS 436, CS5310, EE513) Programming Assignment 3 Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wphiHJb5HKB"
   },
   "source": [
    "### Currently there are lots of professional cartoonizer applications available in the market but most of the them are not freeware, you don't need powerful rendering software or even years of experience to develop such an application(as you will see in this assignment) All you need is essentially a bilateral filter and some edge detection. You are allowed to use opencv for this assigment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Rw4nyfS5HKC"
   },
   "source": [
    "## Step#1\n",
    "### In this step we will be applying a bilateral filter on our input image. A bilateral filter is used for smoothening images and reducing noise, while preserving edges, because a bilateral filter smooths flat regions while keeping edges sharp, it is ideally suited to convert an RGB image into a cartoon. Unfortunately, bilateral filters are orders of magnitudes slower than other smoothing operators (e.g., Gaussian blur). Thus, if speed is important, it might be a good idea to operate on a down-scaled version of the original image first and then upscale it afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OlU28e1M5HKD"
   },
   "outputs": [],
   "source": [
    "#required imports\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "# from google.colab.patches import cv2_imshow\n",
    "from matplotlib import image as mpimg\n",
    "from matplotlib.pyplot import figure\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jaIzhRNmTPmI"
   },
   "source": [
    "Reading \"input.jpg\" through cv2 (BGR format):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dn4aT_YhTRwO"
   },
   "outputs": [],
   "source": [
    "Image = cv2.imread(\"input.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DqxbGuHJT9aU"
   },
   "source": [
    "Converting image from BGR format to RGB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ittU61_3UBN9"
   },
   "outputs": [],
   "source": [
    "RGBImage = cv2.cvtColor(Image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qMT3NYY_UQsF"
   },
   "source": [
    "Using bilateral filter for edge-aware smoothing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cutsucXqUP6f"
   },
   "outputs": [],
   "source": [
    "num_down = 2 # number of downsampling steps \n",
    "\n",
    "# downsample image using Gaussian pyramid(see opencv 'pyrDown()' function)\n",
    "Smoothened = RGBImage\n",
    "for x in range(num_down):\n",
    "  Smoothened = cv2.pyrDown(Smoothened)\n",
    "\n",
    "\n",
    "num_bilateral = 7 # number of bilateral filtering steps\n",
    "\n",
    "FilterSize = 9\n",
    "SigmaColor = 9\n",
    "SigmaSpace = 7\n",
    "\n",
    "# repeatedly apply small bilateral filter instead of applying one large filter\n",
    "for x in range(num_bilateral):\n",
    "  Smoothened = cv2.bilateralFilter(Smoothened, FilterSize, SigmaColor, SigmaSpace)\n",
    "\n",
    "# upsample image to original size (see opencv 'pyrUp()' function)\n",
    "for x in range(num_down):\n",
    "  Smoothened = cv2.pyrUp(Smoothened)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k8_mn4Mn5HKL"
   },
   "source": [
    "## Step#2\n",
    "### In this step we will blur the original image. This is considered as a pre-processing step before we move on towards the edge detection step. We will apply a median filter on the image, which replaces each pixel value with the median value of all the pixels in a small neighborhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4NWQAaZHWIl7"
   },
   "source": [
    "Converting to grayscale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kw28RpUm5HKL"
   },
   "outputs": [],
   "source": [
    "GrayScaled = cv2.cvtColor(RGBImage, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yz_KLxiJWQLV"
   },
   "source": [
    "Applying median blur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iKvzb6xeWTHd"
   },
   "outputs": [],
   "source": [
    "KernelSize = 7\n",
    "MedianBlurred = cv2.medianBlur(GrayScaled, KernelSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "at8-IiX55HKO"
   },
   "source": [
    "## Step#3\n",
    "\n",
    "### In this step we will create an edge mask from the output produced in step#2 using adaptive thresholding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gQa3gxioW1pp"
   },
   "source": [
    "Detecting and enhancing edges (see opencv 'adaptiveThreshold()' function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "waMIt13g5HKO"
   },
   "outputs": [],
   "source": [
    "MaximumValue = 255\n",
    "AdaptiveMethod = cv2.ADAPTIVE_THRESH_MEAN_C\n",
    "ThresholdType = cv2.THRESH_BINARY\n",
    "BlockSize = 9\n",
    "Constant = 2\n",
    "Enhanced = cv2.adaptiveThreshold(MedianBlurred, MaximumValue, AdaptiveMethod, ThresholdType, BlockSize, Constant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mU6BXKQY5HKR"
   },
   "source": [
    "## Final Step\n",
    "\n",
    "### In this step we will combine the output produced in step#1 and step#3 using a bitwise and operator to produce our final output.(Note: You need to convert output from step#3 to color first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vWfz2QEnYPCD"
   },
   "source": [
    "Converting back to color:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eaDR-a3WYSNd"
   },
   "outputs": [],
   "source": [
    "Colored = cv2.cvtColor(Enhanced, cv2.COLOR_GRAY2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "94uKULxJY-DW"
   },
   "source": [
    "Note: 'Smoothened' and 'Colored' might have distinct shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xBq1HL18ZHyi"
   },
   "source": [
    "Adjusting shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SvjxHtm0ZTdX"
   },
   "outputs": [],
   "source": [
    "SmoothenedShape = Smoothened.shape\n",
    "SmoothenedRows = SmoothenedShape[0]\n",
    "SmoothenedColumns = SmoothenedShape[1]\n",
    "\n",
    "ColoredShape = Colored.shape\n",
    "ColoredRows = ColoredShape[0]\n",
    "ColoredColumns = ColoredShape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "buVMevlaY7-O"
   },
   "outputs": [],
   "source": [
    "if SmoothenedRows > ColoredRows:\n",
    "  Difference = SmoothenedRows - ColoredRows\n",
    "  for x in range(Difference):\n",
    "    SmoothenedRows -= 1\n",
    "    Smoothened = np.delete(Smoothened, SmoothenedRows, 0)\n",
    "elif SmoothenedRows < ColoredRows:\n",
    "  Difference = ColoredRows - SmoothenedRows \n",
    "  for x in range(Difference):\n",
    "    ColoredRows -= 1\n",
    "    Colored = np.delete(Colored, ColoredRows, 0)\n",
    "\n",
    "if SmoothenedColumns > ColoredColumns:\n",
    "  Difference = SmoothenedColumns - ColoredColumns\n",
    "  for x in range(Difference):\n",
    "    SmoothenedColumns -= 1\n",
    "    Smoothened = np.delete(Smoothened, SmoothenedColumns, 1)\n",
    "elif SmoothenedColumns < ColoredColumns:\n",
    "  Difference = ColoredColumns - SmoothenedColumns\n",
    "  for x in range(Difference):\n",
    "    ColoredColumns -= 1\n",
    "    Colored = np.delete(Colored, ColoredColumns, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PiJLn22hbTHB"
   },
   "source": [
    "bit-AND with color image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gM6Pb4cjbUYQ"
   },
   "outputs": [],
   "source": [
    "FinalImage = Smoothened & Colored"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PART1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
